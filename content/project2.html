---
title: "Project 2"
output:
  word_document: default
  pdf_document: default
  html_notebook: default
---



<pre class="r"><code>#install.packages(&quot;mlbench&quot;)
#install.packages(&quot;lmtest&quot;)
library(readxl)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lmtest)
#install.packages(&quot;sandwich&quot;)
library(sandwich)
#install.packages(&quot;vegan&quot;)
library(vegan)
#install.packages(&quot;readxl&quot;)

 Book4 &lt;- read_excel(&quot;cereal.xlsx&quot;, skip = 1)
cer&lt;- Book4

cer1&lt;- cer%&gt;%select(-name)
cer1$mfr&lt;-ifelse(cer$mfr== &quot;K&quot;, &quot;K&quot;,&quot;N&quot;)
head(cer1)</code></pre>
<pre><code>## # A tibble: 6 x 5
##   mfr   calories sodium shelf  rating
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;
## 1 N           70    130 Top      68.4
## 2 N          120     15 Top      34.0
## 3 K           70    260 Top      59.4
## 4 K           50    140 Top      93.7
## 5 N          110    200 Top      34.4
## 6 N          110    180 Bottom   29.5</code></pre>
<pre class="r"><code>cer$mfr&lt;- ifelse(cer$mfr== &quot;K&quot;, 1,0)


cer$shelf &lt;- as.factor(cer$shelf)
cer$mfr&lt;- as.factor(cer$mfr)


class_diag &lt;- function(probs,truth){
#CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
acc=sum(diag(tab))/sum(tab)
sens=tab[2,2]/colSums(tab)[2]
spec=tab[1,1]/colSums(tab)[1]
ppv=tab[2,2]/rowSums(tab)[2]
if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
#CALCULATE EXACT AUC
ord&lt;-order(probs, decreasing=TRUE)
probs &lt;- probs[ord]; truth &lt;- truth[ord]
TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))
dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
n &lt;- length(TPR)
auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
data.frame(acc,sens,spec,ppv,auc)
}</code></pre>
<pre class="r"><code>#Question 0.

#My datset is a collection of cereals with their name, whether or not they were manufactured by Kellog&#39;s, calories per serving, sodium in mg, what shelf they are placed on, and overall rating. I got this dataset from Kaggle. In total, there are 77 observations. </code></pre>
<pre class="r"><code>#Question 1.

#MANOVA
man1&lt;-manova(cbind(rating,sodium, calories )~shelf, data=cer)

summary(man1)</code></pre>
<pre><code>##           Df  Pillai approx F num Df den Df   Pr(&gt;F)   
## shelf      2 0.24965   3.4706      6    146 0.003094 **
## Residuals 74                                           
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>#we see that the pvalue is less than .05 and so we reject the null hypothesis and continue on to univariate ANOVA

#univariate ANOVA
summary.aov(man1)</code></pre>
<pre><code>##  Response rating :
##             Df  Sum Sq Mean Sq F value  Pr(&gt;F)  
## shelf        2  1719.8  859.92  4.7928 0.01103 *
## Residuals   74 13277.0  179.42                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response sodium :
##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## shelf        2   9628  4814.1  0.6792 0.5101
## Residuals   74 524489  7087.7               
## 
##  Response calories :
##             Df  Sum Sq Mean Sq F value Pr(&gt;F)
## shelf        2   559.5  279.74  0.7317 0.4845
## Residuals   74 28292.5  382.33</code></pre>
<pre class="r"><code>#we see that for rating and sodium the shelf position differs whereas calories do not

diffmeans&lt;- cer%&gt;%group_by(shelf)%&gt;%summarize(mean(rating),mean(sodium))
diffmeans</code></pre>
<pre><code>## # A tibble: 3 x 3
##   shelf  `mean(rating)` `mean(sodium)`
##   &lt;fct&gt;           &lt;dbl&gt;          &lt;dbl&gt;
## 1 Bottom           46.1           176.
## 2 Middle           35.0           146.
## 3 Top              45.2           159.</code></pre>
<pre class="r"><code>#we see the difference in means in both groups

pairwise.t.test(cer$sodium,cer$shelf,
                p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  cer$sodium and cer$shelf 
## 
##        Bottom Middle
## Middle 0.25   -     
## Top    0.45   0.58  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>#we see that the middle and bottom and top and bottom are significant 
pairwise.t.test(cer$rating,cer$shelf,
                p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  cer$rating and cer$shelf 
## 
##        Bottom Middle
## Middle 0.0093 -     
## Top    0.8050 0.0068
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>#we see that the top and middle are significant

#number of tests: one manova, 3 anova and 6 t tests
.05/10</code></pre>
<pre><code>## [1] 0.005</code></pre>
<pre class="r"><code>#bonferonni is .005
#after bonferonni the bottom and middle and top and middle are significant for sugars but rating is no longer significant

#type one error
1-(.95^10)</code></pre>
<pre><code>## [1] 0.4012631</code></pre>
<pre class="r"><code>#type 1 error is .4012631</code></pre>
<p>I think that this data has passed assumptions for random samples and independent observations. The data does not pass for multivariate normality of DVâ€™s since each group does not have greater than 25 counts. Based on this, it would be difficult for the data to pass other assumptions because the dataset is very small.</p>
<pre class="r"><code>#Question 2.

dists&lt;-cer%&gt;%select(sodium, calories)%&gt;%dist()
adonis(dists~shelf,data=cer)</code></pre>
<pre><code>## 
## Call:
## adonis(formula = dists ~ shelf, data = cer) 
## 
## Permutation: free
## Number of permutations: 999
## 
## Terms added sequentially (first to last)
## 
##           Df SumsOfSqs MeanSqs F.Model     R2 Pr(&gt;F)
## shelf      2     10188  5093.9 0.68191 0.0181  0.505
## Residuals 74    552781  7470.0         0.9819       
## Total     76    562969                 1.0000</code></pre>
<pre class="r"><code>SST&lt;- sum(dists^2)/77
SSW&lt;-cer%&gt;%group_by(shelf)%&gt;%select(sodium,calories)%&gt;%
do(d=dist(.[1:2],&quot;euclidean&quot;))%&gt;%ungroup()%&gt;%
summarize(sum(d[[1]]^2)/20 + sum(d[[2]]^2)/21+ sum(d[[3]]^2)/36)%&gt;%pull

F_obs&lt;-((SST-SSW)/2)/(SSW/74) 

Fs&lt;-replicate(1000,{
new&lt;-cer%&gt;%mutate(shelf=sample(shelf)) #permute the species vector
SSW&lt;-new%&gt;%group_by(shelf)%&gt;%select(sodium,calories)%&gt;%
do(d=dist(.[1:2],&quot;euclidean&quot;))%&gt;%ungroup()%&gt;%
summarize(sum(d[[1]]^2)/20 + sum(d[[2]]^2)/21+ sum(d[[3]]^2)/36)%&gt;%pull
((SST-SSW)/2)/(SSW/74) #calculate new F on randomized data
})
{hist(Fs,prob = T); abline(v=F_obs, col=&quot;red&quot;, add=T)}</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(Fs&gt;F_obs)</code></pre>
<pre><code>## [1] 0.503</code></pre>
<p>Null hypothesis is there is no difference in the mean distance or spread between groups. The alternative hypothesis is that there is a difference in mean distance or spread between groups.The pvalue is very large and so we would fail to reject the null hypothesis.</p>
<pre class="r"><code>#Question 3.
rating_c &lt;- cer$rating - mean(cer$rating)
sugars_c &lt;- cer$sugars - mean(cer$sugars)
calories_c&lt;- cer$calories - mean(cer$calories)
sodium_c&lt;- cer$sodium - mean(cer$sodium)


#linear regresssion
fit&lt;- lm(rating~calories_c*shelf, data = cer)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = rating ~ calories_c * shelf, data = cer)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.730  -6.198  -1.145   4.365  25.476 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             41.1711     2.0449  20.134  &lt; 2e-16 ***
## calories_c              -1.1349     0.2066  -5.493 5.81e-07 ***
## shelfMiddle             -2.5714     2.7830  -0.924 0.358626    
## shelfTop                 4.4053     2.4599   1.791 0.077588 .  
## calories_c:shelfMiddle  -0.2385     0.3076  -0.776 0.440574    
## calories_c:shelfTop      0.7367     0.2129   3.460 0.000918 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.199 on 71 degrees of freedom
## Multiple R-squared:  0.6817, Adjusted R-squared:  0.6593 
## F-statistic: 30.41 on 5 and 71 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>#linear regression plot
qplot(x = calories, y = rating, color = shelf, data = cer) +
stat_smooth(method = &quot;lm&quot;, se = FALSE, fullrange = TRUE)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#checking assumptions
resids&lt;-fit$residuals; fitvals&lt;-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, col=&quot;red&quot;) #checks for linearity and homoskedacity</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_histogram(aes(resids),bins=20) #normality</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_qq(aes(sample=resids))+geom_qq_line(aes(sample=resids), color=&#39;red&#39;) #normality</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-4.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#regression results
coeftest(fit, vcov. = vcovHC(fit))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                        Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)            41.17107    2.20473 18.6740 &lt; 2.2e-16 ***
## calories_c             -1.13489    0.25952 -4.3731 4.115e-05 ***
## shelfMiddle            -2.57143    3.03737 -0.8466  0.400063    
## shelfTop                4.40525    2.59364  1.6985  0.093795 .  
## calories_c:shelfMiddle -0.23854    0.37296 -0.6396  0.524507    
## calories_c:shelfTop     0.73666    0.27155  2.7128  0.008365 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<ul>
<li>Intercept: Predicted rating for a cereal with calories kept constant controlling for shelf placement is 41.17 points.</li>
<li>ShelfMiddle: Controlling for calories, rating for the middle shelf group is 2.57 points lower than the bottom shelf on average.</li>
<li>ShelfTop: Controlling for calories, rating for the top shelf group is 4.4 points higher than the bottom shelf on average.</li>
<li>calories_c: There is a decrease of -1.13 rating points for every one unit increase in sugar on average.</li>
<li>shelfMiddle:calories_c: The slope for calories on rating is .239 times lower for the middle shelf compared to the bottom shelf.</li>
<li>shelfTop:calories_c: The slope for calories on rating is .737 times higher for the top shelf compared to the bottom shelf.</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>The original standard errors were 2.78 and 2.46 for the middle and top shelves while the interaction and rating were all around .2. The significant p values were for calories and top shelf. The robust standard errors increased for the middle shelf and slightly decreased for the top shelf but the interaction between top shelf and calories was now significant.</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Based on the adjusted r-squared value of the original model, we can estimate that rating and shelf level can explain about 65% of the variance in sugar per serving of cereal.</li>
</ul>
</blockquote>
<pre class="r"><code>#Question 4
#bootstrap SE

samp_distn&lt;-replicate(5000, {
boot_dat &lt;- sample_frac(cer, replace=T) #bootstrap your data
fit &lt;- lm(rating~calories_c*shelf, data=boot_dat) #fit model
coef(fit) #save coefs
})
## Estimated SEs
samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) calories_c shelfMiddle shelfTop calories_c:shelfMiddle calories_c:shelfTop
## 1    3.108273  0.1828725    4.373781 3.825137              0.2566512           0.2161973</code></pre>
<p>After running bootstrap errors, the middle and top shelf increased in value compared to the original as well as the robust errors. The calories st. error got smaller. The interaction between calories and middle shelf and top shelf decreased but only slightly. Since the SEs for shelves got bigger, we can assume that the p values also got bigger for those variables.</p>
<pre class="r"><code>#Question 5
head(cer)</code></pre>
<pre><code>## # A tibble: 6 x 6
##   name                      mfr   calories sodium shelf  rating
##   &lt;chr&gt;                     &lt;fct&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;
## 1 100% Bran                 0           70    130 Top      68.4
## 2 100% Natural Bran         0          120     15 Top      34.0
## 3 All-Bran                  1           70    260 Top      59.4
## 4 All-Bran with Extra Fiber 1           50    140 Top      93.7
## 5 Almond Delight            0          110    200 Top      34.4
## 6 Apple Cinnamon Cheerios   0          110    180 Bottom   29.5</code></pre>
<pre class="r"><code>fit3&lt;- glm(mfr~sodium+rating, data = cer, family=binomial(link=&quot;logit&quot;))
coeftest(fit3)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##               Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept) -2.4829901  1.2114207 -2.0497   0.0404 *
## sodium       0.0045534  0.0033596  1.3553   0.1753  
## rating       0.0205273  0.0195455  1.0502   0.2936  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit3))</code></pre>
<pre><code>## (Intercept)      sodium      rating 
##   0.0834932   1.0045637   1.0207395</code></pre>
<pre class="r"><code>prob&lt;- predict(fit3, type = &quot;response&quot;)

#confusion matrix
table(predict=as.numeric(prob&gt;.5),truth=cer$mfr)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict  0  1 Sum
##     0   54 22  76
##     1    0  1   1
##     Sum 54 23  77</code></pre>
<pre class="r"><code>#accuracy
(54+1)/77</code></pre>
<pre><code>## [1] 0.7142857</code></pre>
<pre class="r"><code>#sensitivity
(1/23)</code></pre>
<pre><code>## [1] 0.04347826</code></pre>
<pre class="r"><code>#specificity
54/54</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>#ppv
1/1</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>#plot densit of log odds
odds&lt;-function(p)p/(1-p)
p&lt;-seq(0,1,by=.1)
cbind(p, odds=odds(p))%&gt;%round(4)</code></pre>
<pre><code>##         p   odds
##  [1,] 0.0 0.0000
##  [2,] 0.1 0.1111
##  [3,] 0.2 0.2500
##  [4,] 0.3 0.4286
##  [5,] 0.4 0.6667
##  [6,] 0.5 1.0000
##  [7,] 0.6 1.5000
##  [8,] 0.7 2.3333
##  [9,] 0.8 4.0000
## [10,] 0.9 9.0000
## [11,] 1.0    Inf</code></pre>
<pre class="r"><code>logit&lt;-function(p)log(odds(p))
cbind(p, odds=odds(p),logit=logit(p))%&gt;%round(4)</code></pre>
<pre><code>##         p   odds   logit
##  [1,] 0.0 0.0000    -Inf
##  [2,] 0.1 0.1111 -2.1972
##  [3,] 0.2 0.2500 -1.3863
##  [4,] 0.3 0.4286 -0.8473
##  [5,] 0.4 0.6667 -0.4055
##  [6,] 0.5 1.0000  0.0000
##  [7,] 0.6 1.5000  0.4055
##  [8,] 0.7 2.3333  0.8473
##  [9,] 0.8 4.0000  1.3863
## [10,] 0.9 9.0000  2.1972
## [11,] 1.0    Inf     Inf</code></pre>
<pre class="r"><code>ggplot()+stat_function(aes(p),fun=logit,geom=&quot;line&quot;)+ylab(&quot;g(p)=logit(p)&quot;)+xlab(&quot;p&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" />
&gt; - Intercept: odds of manufacterer being Kellogs when sodium and rating are held constant is .083.
&gt; - sodium: controlling for rating, for every one mg increase in sodium, odds of the manufacterer being Kellogs increase by a factor of 1.0046
&gt; - rating: controlling for sodium, for every one unit increase in rating, odds of the manufacterer being Kellogs increase by a factor of 1.0207</p>
<pre class="r"><code># ROC curve
#install.packages(&quot;plotROC&quot;)
library(plotROC)

cer1$mfr&lt;- as.factor(cer1$mfr)

ROCplot&lt;-ggplot(cer1)+geom_roc(aes(d=mfr,m=prob), n.cuts=0)+
geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2)
ROCplot</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#AUC
calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.4202899</code></pre>
<pre class="r"><code>#needed for function
class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}</code></pre>
<pre class="r"><code>#Question 5 continued

set.seed(1234)
k=10 #choose number of folds
data&lt;-cer[sample(nrow(cer)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(cer)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
## Create training and test sets
train&lt;-data[folds!=i,]
test&lt;-data[folds==i,]
truth&lt;-test$mfr ## Truth labels for fold i
## Train model on training set (all but fold i)
fit&lt;-glm(mfr~rating+sodium,data=train,family=&quot;binomial&quot;)
## Test model on test set (fold i)
probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)
## Get diagnostics for fold i
diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean)</code></pre>
<pre><code>##         acc sens      spec ppv       auc
## 1 0.6821429    0 0.9833333 NaN 0.5257143</code></pre>
<blockquote>
<ul>
<li>The AUC is .45 which would fall below the Bad category.</li>
<li>The out of sample performance for accuracy is .69, the specificity is .98, and the AUC is .45.</li>
</ul>
</blockquote>
<pre class="r"><code>#Question 6

#LASSO
#install.packages(&quot;glmnet&quot;)
library(glmnet)
#install.packages(&quot;plyr&quot;)
library(dplyr)

y&lt;-as.matrix(cer1$mfr) #grab response
x&lt;-model.matrix(mfr~.,data=cer1)[,-1] #grab predictors
head(x)</code></pre>
<pre><code>##   calories sodium shelfMiddle shelfTop   rating
## 1       70    130           0        1 68.40297
## 2      120     15           0        1 33.98368
## 3       70    260           0        1 59.42551
## 4       50    140           0        1 93.70491
## 5      110    200           0        1 34.38484
## 6      110    180           0        0 29.50954</code></pre>
<pre class="r"><code>cv&lt;-cv.glmnet(x,y, family = &quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family = &quot;binomial&quot;, lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 6 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        s0
## (Intercept)  8.534898e-01
## calories     .           
## sodium      -1.590880e-18
## shelfMiddle  .           
## shelfTop     .           
## rating       .</code></pre>
<pre class="r"><code>set.seed(1234)
k=10 #choose number of folds

data&lt;-cer[sample(nrow(cer)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(cer)),breaks=k,labels=F) #create folds

diags&lt;-NULL
for(i in 1:k){
  ## Create training and test sets
  train&lt;-data[folds!=i,] 
  test&lt;-data[folds==i,]
  
  truth&lt;-test$mfr ## Truth labels for fold i
  
  ## Train model on training set (all but fold i)
  fit&lt;-glm(mfr~sodium,data=train,family=&quot;binomial&quot;)
  
  ## Test model on test set (fold i) 
  probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)
  
  ## Get diagnostics for fold i
  diags&lt;-rbind(diags,class_diag(probs,truth))
}


summarize_all(diags,mean)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.6946429    0    1 NaN 0.5385714</code></pre>
<p>The only variable that was retained was the sodium variable. The AUC for question 5 was .45 and the out of sample performance was better as the AUC was .48 and the accuracy went from from .69 to .701. Since these values are higher, we do not assume overfitting.
Add a new chunk by clicking the <em>Insert Chunk</em> button on the toolbar or by pressing <em>Cmd+Option+I</em>.</p>
<p>When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the <em>Preview</em> button or press <em>Cmd+Shift+K</em> to preview the HTML file).</p>
<p>The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike <em>Knit</em>, <em>Preview</em> does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.</p>
